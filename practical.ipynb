{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, input_channels, classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels,out_channels= 20, kernel_size=(5,5))\n",
    "        self.relu1= nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50,kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=800,out_features=500)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=classes)\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.pool1(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.pool2(x)\n",
    "        \n",
    "        # x=self.conv3(x)\n",
    "        # x=self.relu3(x)\n",
    "        # x=self.pool3(x)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr= 0.01\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "train_split = 0.75\n",
    "val_split = 1- train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from torchvision) (1.16.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\krishan walia\\miniconda3\\envs\\envpytorch\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the KMNIST dataset...\n",
      "[INFO] generating the train/validation split...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading the KMNIST dataset...\")\n",
    "train_data = torchvision.datasets.MNIST(root=\"data\", train= True, download = True, transform= torchvision.transforms.ToTensor())\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root=\"data\", train= False, download = True, transform= torchvision.transforms.ToTensor())\n",
    "\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "number_of_train_samples = int(len(train_data)*train_split)\n",
    "\n",
    "number_of_value_samples = int(len(train_data)*val_split)\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [number_of_train_samples, number_of_value_samples], generator= torch.manual_seed(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train, validation, and test data loaders\n",
    "trainDataLoader = torch.utils.data.DataLoader(train_data, shuffle=True,\n",
    "\tbatch_size=batch_size)\n",
    "valDataLoader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "testDataLoader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // batch_size\n",
    "valSteps = len(valDataLoader.dataset) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n",
      "[INFO] training the network...\n",
      "[INFO] EPOCH: 1/5\n",
      "Train loss: 0.408213, Train accuracy: 0.8696\n",
      "Val loss: 0.226640, Val accuracy: 0.9275\n",
      "\n",
      "[INFO] EPOCH: 2/5\n",
      "Train loss: 0.200842, Train accuracy: 0.9376\n",
      "Val loss: 0.154778, Val accuracy: 0.9503\n",
      "\n",
      "[INFO] EPOCH: 3/5\n",
      "Train loss: 0.170080, Train accuracy: 0.9487\n",
      "Val loss: 0.171008, Val accuracy: 0.9474\n",
      "\n",
      "[INFO] EPOCH: 4/5\n",
      "Train loss: 0.158390, Train accuracy: 0.9511\n",
      "Val loss: 0.173160, Val accuracy: 0.9469\n",
      "\n",
      "[INFO] EPOCH: 5/5\n",
      "Train loss: 0.157425, Train accuracy: 0.9523\n",
      "Val loss: 0.150531, Val accuracy: 0.9549\n",
      "\n",
      "[INFO] total time taken to train the model: 155.97s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       0.95      0.98      0.97       980\n",
      "     1 - one       0.99      0.98      0.99      1135\n",
      "     2 - two       0.97      0.95      0.96      1032\n",
      "   3 - three       0.96      0.97      0.97      1010\n",
      "    4 - four       0.97      0.94      0.96       982\n",
      "    5 - five       0.95      0.94      0.95       892\n",
      "     6 - six       0.96      0.96      0.96       958\n",
      "   7 - seven       0.91      0.97      0.94      1028\n",
      "   8 - eight       0.93      0.96      0.95       974\n",
      "    9 - nine       0.95      0.89      0.92      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the LeNet model\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "model = CNN_Model(\n",
    "\tinput_channels=1,\n",
    "\tclasses=len(train_data.dataset.classes))\n",
    "# initialize our optimizer and loss function\n",
    "opt = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "lossFn = nn.NLLLoss()\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "# loop over our epochs\n",
    "for e in range(0, epochs):\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\t# loop over the training set\n",
    "\tfor (x, y) in trainDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t# (x, y) = (x.to(device), y.to(device))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFn(pred, y)\n",
    "\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t# and update the weights\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\t# add the loss to the total training loss so far and\n",
    "\t\t# calculate the number of correct predictions\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttrainCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()\n",
    "\t\t\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in valDataLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t# (x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\ttotalValLoss += lossFn(pred, y)\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\tvalCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\t\ttorch.float).sum().item()\n",
    "\t\t\t\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgValLoss = totalValLoss / valSteps\n",
    "\t# calculate the training and validation accuracy\n",
    "\ttrainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
    "\tvalCorrect = valCorrect / len(valDataLoader.dataset)\n",
    "\t# update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"train_acc\"].append(trainCorrect)\n",
    "\tH[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "\tH[\"val_acc\"].append(valCorrect)\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, epochs))\n",
    "\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, trainCorrect))\n",
    "\tprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "\t\tavgValLoss, valCorrect))\n",
    "\t\n",
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))\n",
    "# we can now evaluate the network on the test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# turn off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "\t# set the model in evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# initialize a list to store our predictions\n",
    "\tpreds = []\n",
    "\t# loop over the test set\n",
    "\tfor (x, y) in testDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t# x = x.to(device)\n",
    "\t\t# make the predictions and add them to the list\n",
    "\t\tpred = model(x)\n",
    "\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "# generate a classification report\n",
    "print(classification_report(test_data.targets.cpu().numpy(),\n",
    "\tnp.array(preds), target_names=test_data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"MNIST_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
